{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e36ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PCA Function\n",
    "def pca(X, n_components=0):\n",
    "    if n_components == 0:\n",
    "        n_components = round(0.95 * len(X))\n",
    "    mean_vector = np.mean(X, axis=0)\n",
    "    covariance_matrix = np.cov(X, rowvar=False)\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
    "    ind = np.argsort(eigen_values)[::-1]\n",
    "    sorted_eigen_values = eigen_values[ind]\n",
    "    sorted_eigen_vectors = eigen_vectors[ind]\n",
    "    final_eigen_vectors = sorted_eigen_vectors[:, :n_components]\n",
    "    X_transformed = np.dot(X, final_eigen_vectors)\n",
    "    return X_transformed\n",
    "\n",
    "# Importing Dataset\n",
    "dataset = pd.read_csv(\"gender.csv\")\n",
    "dataset.rename( columns={'Unnamed: 0':'a'}, inplace=True )\n",
    "dataset.rename( columns={'Unnamed: 1':'target'}, inplace=True )\n",
    "le = LabelEncoder()\n",
    "dataset.iloc[:,1]=le.fit_transform(dataset.iloc[:,1])\n",
    "# Test-Train Split\n",
    "types = dataset.iloc[:, 1].unique()\n",
    "test_df = pd.DataFrame()\n",
    "train_df = pd.DataFrame()\n",
    "for t in types:\n",
    "    type_df = dataset[dataset.iloc[:, 1] == t]\n",
    "    train_df = pd.concat([train_df, type_df.iloc[10:]])\n",
    "    test_df = pd.concat([test_df, type_df.iloc[:10]])\n",
    "\n",
    "X_train = train_df.iloc[:, 2:].values\n",
    "X_test = test_df.iloc[:, 2:].values\n",
    "y_train = train_df.iloc[:, 1].values\n",
    "y_test = test_df.iloc[:, 1].values\n",
    "\n",
    "\n",
    "\n",
    "# Before PCA\n",
    "mean_vectors = []\n",
    "covariance_matrices = []\n",
    "inverse_covariance_matrices = []\n",
    "det_covariance_matrices = []\n",
    "\n",
    "for c in np.unique(y_train):\n",
    "    class_data = X_train[y_train == c]\n",
    "    mean_vectors.append(np.mean(class_data, axis=0))\n",
    "    covariance_matrices.append(np.cov(class_data, rowvar=False))\n",
    "    inverse_covariance_matrices.append(np.linalg.inv(covariance_matrices[-1]))\n",
    "    det_covariance_matrices.append(sp.Matrix(covariance_matrices[-1]).det())\n",
    "\n",
    "y_pred_before = []\n",
    "print(X_train[0])\n",
    "dimensions = len(X_train[0])\n",
    "\n",
    "for X in X_test:\n",
    "    probability_values = {}\n",
    "    class_count = 0\n",
    "    for c in np.unique(y_train):\n",
    "        p_xw = np.exp(-0.5 * np.dot(np.dot((X - mean_vectors[class_count]).T, inverse_covariance_matrices[class_count]), (X - mean_vectors[class_count]))) / (((2 * np.pi) ** (dimensions / 2)) * np.power(det_covariance_matrices[class_count], 0.5))\n",
    "        p_wx = p_xw * np.sum(y_train == c) / len(y_train)\n",
    "        probability_values[c] = p_wx\n",
    "        class_count += 1\n",
    "    y_pred_before.append(max(probability_values, key=probability_values.get))\n",
    "\n",
    "final_df_before = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_before})\n",
    "accuracy = accuracy_score(y_test, y_pred_before)\n",
    "print(f\"The Accuracy of this model before PCA is {accuracy * 100}%\")\n",
    "\n",
    "\n",
    "dataset=pca(dataset)\n",
    "dataset=pd.DataFrame(dataset)\n",
    "# Test-Train Split\n",
    "types = dataset.iloc[:, 1].unique()\n",
    "test_df = pd.DataFrame()\n",
    "train_df = pd.DataFrame()\n",
    "for t in types:\n",
    "    type_df = dataset[dataset.iloc[:, 1] == t]\n",
    "    train_df = pd.concat([train_df, type_df.iloc[10:]])\n",
    "    test_df = pd.concat([test_df, type_df.iloc[:10]])\n",
    "\n",
    "X_train = train_df.iloc[:, 2:].values\n",
    "X_test = test_df.iloc[:, 2:].values\n",
    "y_train = train_df.iloc[:, 1].values\n",
    "y_test = test_df.iloc[:, 1].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean_vectors = []\n",
    "covariance_matrices = []\n",
    "inverse_covariance_matrices = []\n",
    "det_covariance_matrices = []  # Initialize as an empty list\n",
    "dimensions = len(X_train[0])\n",
    "\n",
    "for c in np.unique(y_train):\n",
    "    class_data = X_train[y_train == c]\n",
    "    mean_vectors.append(np.mean(class_data, axis=0))\n",
    "    covariance_matrices.append(np.cov(class_data, rowvar=False))\n",
    "    inverse_covariance_matrices.append(np.linalg.inv(covariance_matrices[-1]))\n",
    "    det_covariance_matrices.append(sp.Matrix(covariance_matrices[-1]).det())\n",
    "\n",
    "y_pred_after = []\n",
    "for X in X_test:\n",
    "    probability_values = {}\n",
    "    class_count = 0\n",
    "    for c in np.unique(y_train):\n",
    "        p_xw = np.exp(-0.5 * np.dot(np.dot((X - mean_vectors[class_count]).T, inverse_covariance_matrices[class_count]), (X - mean_vectors[class_count]))) / (((2 * np.pi) ** (dimensions / 2)) * np.power(det_covariance_matrices[class_count], 0.5))\n",
    "        p_wx = p_xw * np.sum(y_train == c) / len(y_train)\n",
    "        probability_values[c] = p_wx\n",
    "        class_count += 1\n",
    "    y_pred_after.append(max(probability_values, key=probability_values.get))\n",
    "\n",
    "    \n",
    "    \n",
    "print(y_pred_after)\n",
    "final_df_after = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_after})\n",
    "accuracy = accuracy_score(y_test, y_pred_after)\n",
    "print(f\"The Accuracy of this model after PCA is {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2da07a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.066420</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.066105</td>\n",
       "      <td>-0.041232</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>-0.158467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>-0.046754</td>\n",
       "      <td>-0.118619</td>\n",
       "      <td>-0.163774</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>-0.076400</td>\n",
       "      <td>0.107497</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.030614</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>-0.050324</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>-0.063818</td>\n",
       "      <td>-0.019530</td>\n",
       "      <td>-0.119905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.028108</td>\n",
       "      <td>0.040618</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>-0.141244</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.080610</td>\n",
       "      <td>-0.015930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.096178</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>-0.035388</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>-0.018634</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>-0.139786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111141</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>-0.029222</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>-0.222173</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>0.093428</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.057652</td>\n",
       "      <td>0.086116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.103057</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>-0.035873</td>\n",
       "      <td>-0.028163</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>-0.017016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100793</td>\n",
       "      <td>-0.002644</td>\n",
       "      <td>-0.023388</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>-0.015100</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.125815</td>\n",
       "      <td>0.120046</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>-0.042901</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>-0.049677</td>\n",
       "      <td>-0.054258</td>\n",
       "      <td>-0.130758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.039926</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>-0.056852</td>\n",
       "      <td>-0.076700</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.084135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>796</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.164731</td>\n",
       "      <td>0.064301</td>\n",
       "      <td>0.058630</td>\n",
       "      <td>-0.017420</td>\n",
       "      <td>-0.157600</td>\n",
       "      <td>-0.022536</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.072739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095115</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>-0.170753</td>\n",
       "      <td>-0.136630</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>797</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.092913</td>\n",
       "      <td>-0.101745</td>\n",
       "      <td>-0.083153</td>\n",
       "      <td>-0.028159</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>-0.114513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.119846</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>-0.096594</td>\n",
       "      <td>-0.084553</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.030732</td>\n",
       "      <td>-0.083713</td>\n",
       "      <td>0.064970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.202852</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>-0.047156</td>\n",
       "      <td>-0.140062</td>\n",
       "      <td>-0.080246</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>-0.122083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>-0.023112</td>\n",
       "      <td>-0.030452</td>\n",
       "      <td>-0.154243</td>\n",
       "      <td>-0.188270</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>-0.006257</td>\n",
       "      <td>0.039977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.088300</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.049627</td>\n",
       "      <td>-0.026011</td>\n",
       "      <td>-0.172773</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>0.042710</td>\n",
       "      <td>-0.161852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>-0.154515</td>\n",
       "      <td>-0.127736</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>-0.016942</td>\n",
       "      <td>0.048071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.156201</td>\n",
       "      <td>0.055165</td>\n",
       "      <td>0.142716</td>\n",
       "      <td>-0.115393</td>\n",
       "      <td>-0.128982</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.037305</td>\n",
       "      <td>-0.101402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>-0.045738</td>\n",
       "      <td>-0.110557</td>\n",
       "      <td>-0.014995</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>-0.028856</td>\n",
       "      <td>0.075323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       a Unnamed: 1         0         1         2         3         4  \\\n",
       "0      1       male -0.066420  0.151611  0.027740  0.052771 -0.066105   \n",
       "1      2       male -0.030614  0.049667  0.008084 -0.050324  0.007649   \n",
       "2      3       male -0.096178  0.061127  0.035326 -0.035388 -0.090728   \n",
       "3      4       male -0.103057  0.085044  0.078333 -0.035873 -0.028163   \n",
       "4      5       male -0.125815  0.120046  0.023131 -0.042901  0.038215   \n",
       "..   ...        ...       ...       ...       ...       ...       ...   \n",
       "795  796     female -0.164731  0.064301  0.058630 -0.017420 -0.157600   \n",
       "796  797     female -0.095308  0.051095  0.092913 -0.101745 -0.083153   \n",
       "797  798     female -0.202852  0.037039  0.079731 -0.047156 -0.140062   \n",
       "798  799     female -0.088300  0.063530  0.049627 -0.026011 -0.172773   \n",
       "799  800     female -0.156201  0.055165  0.142716 -0.115393 -0.128982   \n",
       "\n",
       "            5         6         7  ...       118       119       120  \\\n",
       "0   -0.041232 -0.002637 -0.158467  ...  0.025989 -0.001087  0.027260   \n",
       "1   -0.063818 -0.019530 -0.119905  ...  0.044229 -0.023900 -0.028108   \n",
       "2   -0.018634 -0.024315 -0.139786  ...  0.111141  0.059436 -0.029222   \n",
       "3    0.004924  0.007829 -0.017016  ...  0.100793 -0.002644 -0.023388   \n",
       "4   -0.049677 -0.054258 -0.130758  ...  0.090197  0.067527  0.039926   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795 -0.022536  0.002864 -0.072739  ...  0.095115  0.007198 -0.004655   \n",
       "796 -0.028159  0.009090 -0.114513  ...  0.056078  0.119846  0.087470   \n",
       "797 -0.080246  0.057668 -0.122083  ...  0.066954  0.035684 -0.023112   \n",
       "798  0.086218  0.042710 -0.161852  ...  0.039460  0.067547  0.040426   \n",
       "799 -0.139830 -0.037305 -0.101402  ...  0.024955  0.066980 -0.002332   \n",
       "\n",
       "          121       122       123       124       125       126       127  \n",
       "0   -0.046754 -0.118619 -0.163774 -0.000590 -0.076400  0.107497  0.001567  \n",
       "1    0.040618 -0.146579 -0.141244  0.016162  0.017638  0.080610 -0.015930  \n",
       "2    0.042115 -0.222173 -0.116908  0.093428  0.017391  0.057652  0.086116  \n",
       "3    0.029497 -0.139830 -0.119243  0.005306 -0.015100  0.161575  0.062462  \n",
       "4    0.047469 -0.056852 -0.076700  0.004966  0.028171  0.026041  0.084135  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "795  0.023957 -0.170753 -0.136630  0.041614  0.031600  0.019064  0.004384  \n",
       "796  0.017481 -0.096594 -0.084553  0.037709  0.030732 -0.083713  0.064970  \n",
       "797 -0.030452 -0.154243 -0.188270  0.071086  0.037384 -0.006257  0.039977  \n",
       "798  0.028007 -0.154515 -0.127736  0.046967  0.009701 -0.016942  0.048071  \n",
       "799 -0.045738 -0.110557 -0.014995 -0.002124 -0.010298 -0.028856  0.075323  \n",
       "\n",
       "[800 rows x 130 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"gender.csv\")\n",
    "dataset.rename( columns={'Unnamed: 0':'a'}, inplace=True )\n",
    "dataset.drop(\"a\",axis=1)\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44eb7f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41516bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.066420</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.066105</td>\n",
       "      <td>-0.041232</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>-0.158467</td>\n",
       "      <td>0.130467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>-0.046754</td>\n",
       "      <td>-0.118619</td>\n",
       "      <td>-0.163774</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>-0.076400</td>\n",
       "      <td>0.107497</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.030614</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>-0.050324</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>-0.063818</td>\n",
       "      <td>-0.019530</td>\n",
       "      <td>-0.119905</td>\n",
       "      <td>0.186553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.028108</td>\n",
       "      <td>0.040618</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>-0.141244</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.080610</td>\n",
       "      <td>-0.015930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.096178</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>-0.035388</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>-0.018634</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>-0.139786</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111141</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>-0.029222</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>-0.222173</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>0.093428</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.057652</td>\n",
       "      <td>0.086116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.103057</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>-0.035873</td>\n",
       "      <td>-0.028163</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>-0.017016</td>\n",
       "      <td>0.114907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100793</td>\n",
       "      <td>-0.002644</td>\n",
       "      <td>-0.023388</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>-0.015100</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.125815</td>\n",
       "      <td>0.120046</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>-0.042901</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>-0.049677</td>\n",
       "      <td>-0.054258</td>\n",
       "      <td>-0.130758</td>\n",
       "      <td>0.173457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.039926</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>-0.056852</td>\n",
       "      <td>-0.076700</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.084135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.164731</td>\n",
       "      <td>0.064301</td>\n",
       "      <td>0.058630</td>\n",
       "      <td>-0.017420</td>\n",
       "      <td>-0.157600</td>\n",
       "      <td>-0.022536</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.072739</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095115</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>-0.170753</td>\n",
       "      <td>-0.136630</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.092913</td>\n",
       "      <td>-0.101745</td>\n",
       "      <td>-0.083153</td>\n",
       "      <td>-0.028159</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>-0.114513</td>\n",
       "      <td>0.157421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.119846</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>-0.096594</td>\n",
       "      <td>-0.084553</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.030732</td>\n",
       "      <td>-0.083713</td>\n",
       "      <td>0.064970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.202852</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>-0.047156</td>\n",
       "      <td>-0.140062</td>\n",
       "      <td>-0.080246</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>-0.122083</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>-0.023112</td>\n",
       "      <td>-0.030452</td>\n",
       "      <td>-0.154243</td>\n",
       "      <td>-0.188270</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>-0.006257</td>\n",
       "      <td>0.039977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.088300</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.049627</td>\n",
       "      <td>-0.026011</td>\n",
       "      <td>-0.172773</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>0.042710</td>\n",
       "      <td>-0.161852</td>\n",
       "      <td>0.185083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>-0.154515</td>\n",
       "      <td>-0.127736</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>-0.016942</td>\n",
       "      <td>0.048071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.156201</td>\n",
       "      <td>0.055165</td>\n",
       "      <td>0.142716</td>\n",
       "      <td>-0.115393</td>\n",
       "      <td>-0.128982</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.037305</td>\n",
       "      <td>-0.101402</td>\n",
       "      <td>0.048473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>-0.045738</td>\n",
       "      <td>-0.110557</td>\n",
       "      <td>-0.014995</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>-0.028856</td>\n",
       "      <td>0.075323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target         0         1         2         3         4         5  \\\n",
       "0      male -0.066420  0.151611  0.027740  0.052771 -0.066105 -0.041232   \n",
       "1      male -0.030614  0.049667  0.008084 -0.050324  0.007649 -0.063818   \n",
       "2      male -0.096178  0.061127  0.035326 -0.035388 -0.090728 -0.018634   \n",
       "3      male -0.103057  0.085044  0.078333 -0.035873 -0.028163  0.004924   \n",
       "4      male -0.125815  0.120046  0.023131 -0.042901  0.038215 -0.049677   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "795  female -0.164731  0.064301  0.058630 -0.017420 -0.157600 -0.022536   \n",
       "796  female -0.095308  0.051095  0.092913 -0.101745 -0.083153 -0.028159   \n",
       "797  female -0.202852  0.037039  0.079731 -0.047156 -0.140062 -0.080246   \n",
       "798  female -0.088300  0.063530  0.049627 -0.026011 -0.172773  0.086218   \n",
       "799  female -0.156201  0.055165  0.142716 -0.115393 -0.128982 -0.139830   \n",
       "\n",
       "            6         7         8  ...       118       119       120  \\\n",
       "0   -0.002637 -0.158467  0.130467  ...  0.025989 -0.001087  0.027260   \n",
       "1   -0.019530 -0.119905  0.186553  ...  0.044229 -0.023900 -0.028108   \n",
       "2   -0.024315 -0.139786  0.052211  ...  0.111141  0.059436 -0.029222   \n",
       "3    0.007829 -0.017016  0.114907  ...  0.100793 -0.002644 -0.023388   \n",
       "4   -0.054258 -0.130758  0.173457  ...  0.090197  0.067527  0.039926   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  0.002864 -0.072739  0.030554  ...  0.095115  0.007198 -0.004655   \n",
       "796  0.009090 -0.114513  0.157421  ...  0.056078  0.119846  0.087470   \n",
       "797  0.057668 -0.122083  0.165443  ...  0.066954  0.035684 -0.023112   \n",
       "798  0.042710 -0.161852  0.185083  ...  0.039460  0.067547  0.040426   \n",
       "799 -0.037305 -0.101402  0.048473  ...  0.024955  0.066980 -0.002332   \n",
       "\n",
       "          121       122       123       124       125       126       127  \n",
       "0   -0.046754 -0.118619 -0.163774 -0.000590 -0.076400  0.107497  0.001567  \n",
       "1    0.040618 -0.146579 -0.141244  0.016162  0.017638  0.080610 -0.015930  \n",
       "2    0.042115 -0.222173 -0.116908  0.093428  0.017391  0.057652  0.086116  \n",
       "3    0.029497 -0.139830 -0.119243  0.005306 -0.015100  0.161575  0.062462  \n",
       "4    0.047469 -0.056852 -0.076700  0.004966  0.028171  0.026041  0.084135  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "795  0.023957 -0.170753 -0.136630  0.041614  0.031600  0.019064  0.004384  \n",
       "796  0.017481 -0.096594 -0.084553  0.037709  0.030732 -0.083713  0.064970  \n",
       "797 -0.030452 -0.154243 -0.188270  0.071086  0.037384 -0.006257  0.039977  \n",
       "798  0.028007 -0.154515 -0.127736  0.046967  0.009701 -0.016942  0.048071  \n",
       "799 -0.045738 -0.110557 -0.014995 -0.002124 -0.010298 -0.028856  0.075323  \n",
       "\n",
       "[800 rows x 129 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9ab774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4d70351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998172</td>\n",
       "      <td>0.890546</td>\n",
       "      <td>0.223747</td>\n",
       "      <td>-0.071050</td>\n",
       "      <td>-0.138517</td>\n",
       "      <td>0.134040</td>\n",
       "      <td>-0.124984</td>\n",
       "      <td>0.254958</td>\n",
       "      <td>-0.108636</td>\n",
       "      <td>0.053236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072756</td>\n",
       "      <td>0.104029</td>\n",
       "      <td>0.036584</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>-0.222778</td>\n",
       "      <td>-0.148006</td>\n",
       "      <td>-0.068748</td>\n",
       "      <td>-0.082201</td>\n",
       "      <td>-0.031613</td>\n",
       "      <td>-0.102967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.998202</td>\n",
       "      <td>0.889296</td>\n",
       "      <td>0.132328</td>\n",
       "      <td>-0.232906</td>\n",
       "      <td>-0.156522</td>\n",
       "      <td>0.164608</td>\n",
       "      <td>-0.128925</td>\n",
       "      <td>0.126367</td>\n",
       "      <td>-0.073777</td>\n",
       "      <td>0.108880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081243</td>\n",
       "      <td>0.069002</td>\n",
       "      <td>0.034198</td>\n",
       "      <td>-0.013571</td>\n",
       "      <td>-0.181246</td>\n",
       "      <td>-0.081752</td>\n",
       "      <td>-0.100546</td>\n",
       "      <td>-0.118350</td>\n",
       "      <td>-0.029352</td>\n",
       "      <td>-0.083704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.998235</td>\n",
       "      <td>0.861548</td>\n",
       "      <td>0.132510</td>\n",
       "      <td>-0.183648</td>\n",
       "      <td>-0.128215</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>-0.323645</td>\n",
       "      <td>0.114504</td>\n",
       "      <td>0.027655</td>\n",
       "      <td>-0.024123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116013</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.071478</td>\n",
       "      <td>-0.158942</td>\n",
       "      <td>-0.028477</td>\n",
       "      <td>-0.102812</td>\n",
       "      <td>-0.073259</td>\n",
       "      <td>-0.028956</td>\n",
       "      <td>0.056129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.998145</td>\n",
       "      <td>0.911621</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>-0.101627</td>\n",
       "      <td>-0.215554</td>\n",
       "      <td>0.086198</td>\n",
       "      <td>-0.060832</td>\n",
       "      <td>0.285304</td>\n",
       "      <td>0.018240</td>\n",
       "      <td>0.084380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079087</td>\n",
       "      <td>0.062516</td>\n",
       "      <td>0.072578</td>\n",
       "      <td>0.050592</td>\n",
       "      <td>-0.153164</td>\n",
       "      <td>-0.063272</td>\n",
       "      <td>-0.101974</td>\n",
       "      <td>-0.117423</td>\n",
       "      <td>-0.008599</td>\n",
       "      <td>-0.032305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.998140</td>\n",
       "      <td>0.913434</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>-0.110316</td>\n",
       "      <td>-0.191538</td>\n",
       "      <td>0.066674</td>\n",
       "      <td>-0.036182</td>\n",
       "      <td>0.146460</td>\n",
       "      <td>-0.041239</td>\n",
       "      <td>0.069098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034279</td>\n",
       "      <td>0.028281</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.024356</td>\n",
       "      <td>-0.153345</td>\n",
       "      <td>-0.071569</td>\n",
       "      <td>-0.066146</td>\n",
       "      <td>-0.052803</td>\n",
       "      <td>-0.061366</td>\n",
       "      <td>-0.037596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795.998586</td>\n",
       "      <td>1.484719</td>\n",
       "      <td>0.433064</td>\n",
       "      <td>-0.176306</td>\n",
       "      <td>-0.076159</td>\n",
       "      <td>0.073975</td>\n",
       "      <td>-0.149667</td>\n",
       "      <td>0.132612</td>\n",
       "      <td>-0.057989</td>\n",
       "      <td>-0.041403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116304</td>\n",
       "      <td>0.015676</td>\n",
       "      <td>0.063921</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.079259</td>\n",
       "      <td>-0.062028</td>\n",
       "      <td>-0.091801</td>\n",
       "      <td>-0.090257</td>\n",
       "      <td>0.018059</td>\n",
       "      <td>0.076938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796.998704</td>\n",
       "      <td>1.419265</td>\n",
       "      <td>0.183412</td>\n",
       "      <td>-0.232005</td>\n",
       "      <td>-0.163499</td>\n",
       "      <td>0.128282</td>\n",
       "      <td>-0.177558</td>\n",
       "      <td>0.163624</td>\n",
       "      <td>0.131282</td>\n",
       "      <td>0.120889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117662</td>\n",
       "      <td>0.064044</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>-0.022408</td>\n",
       "      <td>-0.126137</td>\n",
       "      <td>-0.045763</td>\n",
       "      <td>-0.081437</td>\n",
       "      <td>-0.093692</td>\n",
       "      <td>0.020490</td>\n",
       "      <td>0.061892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797.998702</td>\n",
       "      <td>1.431059</td>\n",
       "      <td>0.346479</td>\n",
       "      <td>-0.217069</td>\n",
       "      <td>-0.049557</td>\n",
       "      <td>0.104853</td>\n",
       "      <td>-0.103037</td>\n",
       "      <td>0.242186</td>\n",
       "      <td>0.048959</td>\n",
       "      <td>-0.009526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096960</td>\n",
       "      <td>0.034040</td>\n",
       "      <td>0.047425</td>\n",
       "      <td>-0.001801</td>\n",
       "      <td>-0.032316</td>\n",
       "      <td>-0.075472</td>\n",
       "      <td>-0.051196</td>\n",
       "      <td>-0.126643</td>\n",
       "      <td>-0.005328</td>\n",
       "      <td>0.040147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798.998678</td>\n",
       "      <td>1.443258</td>\n",
       "      <td>0.430054</td>\n",
       "      <td>-0.059469</td>\n",
       "      <td>-0.159491</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>-0.193310</td>\n",
       "      <td>0.126656</td>\n",
       "      <td>-0.129891</td>\n",
       "      <td>-0.024259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083806</td>\n",
       "      <td>0.054918</td>\n",
       "      <td>0.032777</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>-0.079716</td>\n",
       "      <td>-0.066676</td>\n",
       "      <td>-0.083959</td>\n",
       "      <td>-0.127937</td>\n",
       "      <td>-0.042245</td>\n",
       "      <td>0.032562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799.998702</td>\n",
       "      <td>1.429495</td>\n",
       "      <td>0.144792</td>\n",
       "      <td>-0.220238</td>\n",
       "      <td>-0.161944</td>\n",
       "      <td>0.067239</td>\n",
       "      <td>-0.317241</td>\n",
       "      <td>0.245310</td>\n",
       "      <td>0.094265</td>\n",
       "      <td>0.206439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035966</td>\n",
       "      <td>0.071744</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>0.054076</td>\n",
       "      <td>-0.113664</td>\n",
       "      <td>-0.081681</td>\n",
       "      <td>-0.087495</td>\n",
       "      <td>-0.038373</td>\n",
       "      <td>-0.107438</td>\n",
       "      <td>0.089829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.998172  0.890546  0.223747 -0.071050 -0.138517  0.134040 -0.124984   \n",
       "1      1.998202  0.889296  0.132328 -0.232906 -0.156522  0.164608 -0.128925   \n",
       "2      2.998235  0.861548  0.132510 -0.183648 -0.128215  0.033146 -0.323645   \n",
       "3      3.998145  0.911621  0.288676 -0.101627 -0.215554  0.086198 -0.060832   \n",
       "4      4.998140  0.913434  0.010956 -0.110316 -0.191538  0.066674 -0.036182   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "795  795.998586  1.484719  0.433064 -0.176306 -0.076159  0.073975 -0.149667   \n",
       "796  796.998704  1.419265  0.183412 -0.232005 -0.163499  0.128282 -0.177558   \n",
       "797  797.998702  1.431059  0.346479 -0.217069 -0.049557  0.104853 -0.103037   \n",
       "798  798.998678  1.443258  0.430054 -0.059469 -0.159491  0.047672 -0.193310   \n",
       "799  799.998702  1.429495  0.144792 -0.220238 -0.161944  0.067239 -0.317241   \n",
       "\n",
       "          7         8         9    ...       120       121       122  \\\n",
       "0    0.254958 -0.108636  0.053236  ... -0.072756  0.104029  0.036584   \n",
       "1    0.126367 -0.073777  0.108880  ... -0.081243  0.069002  0.034198   \n",
       "2    0.114504  0.027655 -0.024123  ... -0.116013  0.058775  0.020336   \n",
       "3    0.285304  0.018240  0.084380  ... -0.079087  0.062516  0.072578   \n",
       "4    0.146460 -0.041239  0.069098  ... -0.034279  0.028281  0.014159   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  0.132612 -0.057989 -0.041403  ... -0.116304  0.015676  0.063921   \n",
       "796  0.163624  0.131282  0.120889  ... -0.117662  0.064044  0.053097   \n",
       "797  0.242186  0.048959 -0.009526  ... -0.096960  0.034040  0.047425   \n",
       "798  0.126656 -0.129891 -0.024259  ... -0.083806  0.054918  0.032777   \n",
       "799  0.245310  0.094265  0.206439  ... -0.035966  0.071744  0.042280   \n",
       "\n",
       "          123       124       125       126       127       128       129  \n",
       "0    0.039078 -0.222778 -0.148006 -0.068748 -0.082201 -0.031613 -0.102967  \n",
       "1   -0.013571 -0.181246 -0.081752 -0.100546 -0.118350 -0.029352 -0.083704  \n",
       "2    0.071478 -0.158942 -0.028477 -0.102812 -0.073259 -0.028956  0.056129  \n",
       "3    0.050592 -0.153164 -0.063272 -0.101974 -0.117423 -0.008599 -0.032305  \n",
       "4    0.024356 -0.153345 -0.071569 -0.066146 -0.052803 -0.061366 -0.037596  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "795 -0.001151 -0.079259 -0.062028 -0.091801 -0.090257  0.018059  0.076938  \n",
       "796 -0.022408 -0.126137 -0.045763 -0.081437 -0.093692  0.020490  0.061892  \n",
       "797 -0.001801 -0.032316 -0.075472 -0.051196 -0.126643 -0.005328  0.040147  \n",
       "798  0.018923 -0.079716 -0.066676 -0.083959 -0.127937 -0.042245  0.032562  \n",
       "799  0.054076 -0.113664 -0.081681 -0.087495 -0.038373 -0.107438  0.089829  \n",
       "\n",
       "[800 rows x 130 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba9356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of this model before PCA is 85.0%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (19,) (128,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 108>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    106\u001b[0m bc\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    107\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pca(X_test)  \n\u001b[1;32m--> 108\u001b[0m y_pred_after \u001b[38;5;241m=\u001b[39m \u001b[43mbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m final_df_after \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_pred_after})\n\u001b[0;32m    111\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_after)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mBayesClassifier.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     60\u001b[0m class_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses:\n\u001b[1;32m---> 62\u001b[0m     p_xw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mdot((\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_vectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_count\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse_covariance_matrices[class_count]), (X \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_vectors[class_count]))) \u001b[38;5;241m/\u001b[39m (((\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdet_covariance_matrices[c], \u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m     63\u001b[0m     p_wx \u001b[38;5;241m=\u001b[39m p_xw \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapriori_probabilities[class_count]\n\u001b[0;32m     64\u001b[0m     probability_values[c] \u001b[38;5;241m=\u001b[39m p_wx\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (19,) (128,) "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PCA Function\n",
    "def pca(X, n_components=0):\n",
    "    if n_components == 0:\n",
    "        n_components = round(0.95 * len(X))\n",
    "    mean_vector = np.mean(X, axis=0)\n",
    "    covariance_matrix = np.cov(X, rowvar=False)\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
    "    ind = np.argsort(eigen_values)[::-1]\n",
    "    sorted_eigen_values = eigen_values[ind]\n",
    "    sorted_eigen_vectors = eigen_vectors[ind]\n",
    "    final_eigen_vectors = sorted_eigen_vectors[:, :n_components]\n",
    "    X_transformed = np.dot(X, final_eigen_vectors)\n",
    "    return X_transformed\n",
    "\n",
    "# Bayes Classifier\n",
    "class BayesClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes, self.class_counts = np.unique(y_train, return_counts=True)\n",
    "        self.no_of_classes = len(self.classes)\n",
    "        self.total_data_points = len(y_train)\n",
    "        self.apriori_probabilities = self.class_counts / self.total_data_points\n",
    "        self.class_split_training_data = {}\n",
    "        for c in self.classes:\n",
    "            self.class_split_training_data[c] = []\n",
    "            for j in range(len(y_train)):\n",
    "                if c == y_train[j]:\n",
    "                    self.class_split_training_data[c].append(X_train[j])\n",
    "            self.class_split_training_data[c] = np.array(self.class_split_training_data[c])\n",
    "        self.mean_vectors = []\n",
    "        for c in self.classes:\n",
    "            self.mean_vectors.append(np.mean(self.class_split_training_data[c], axis=0))\n",
    "        self.covariance_matrices = []\n",
    "        for c in self.classes:\n",
    "            self.covariance_matrices.append(np.cov(self.class_split_training_data[c], rowvar=False))\n",
    "        self.inverse_covariance_matrices = []\n",
    "        for c in range(len(self.classes)):\n",
    "            self.inverse_covariance_matrices.append(np.linalg.inv(self.covariance_matrices[c]))\n",
    "        self.dimensions = len(X_train[0])\n",
    "        self.det_covariance_matrices = []\n",
    "        for c in range(len(self.classes)):\n",
    "            self.det_covariance_matrices.append(sp.Matrix(self.covariance_matrices[c]).det())\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for X in X_test:\n",
    "            probability_values = {}\n",
    "            class_count = 0\n",
    "            for c in self.classes:\n",
    "                p_xw = np.exp(-0.5 * np.dot(np.dot((X - self.mean_vectors[class_count]).T, self.inverse_covariance_matrices[class_count]), (X - self.mean_vectors[class_count]))) / (((2 * np.pi) ** (self.dimensions / 2)) * np.power(self.det_covariance_matrices[c], 0.5))\n",
    "                p_wx = p_xw * self.apriori_probabilities[class_count]\n",
    "                probability_values[c] = p_wx\n",
    "                class_count += 1\n",
    "            y_pred.append(max(probability_values, key=probability_values.get))\n",
    "        y_pred = np.array(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "# Importing Dataset\n",
    "dataset = pd.read_csv(\"gender.csv\")\n",
    "\n",
    "# Test-Train Split\n",
    "types = dataset.iloc[:, 1].unique()\n",
    "test_df = pd.DataFrame()\n",
    "train_df = pd.DataFrame()\n",
    "for t in types:\n",
    "    type_df = dataset[dataset.iloc[:, 1] == t]\n",
    "    train_df = pd.concat([train_df, type_df.iloc[10:]])\n",
    "    test_df = pd.concat([test_df, type_df.iloc[:10]])\n",
    "\n",
    "X_train = train_df.iloc[:, 2:].values\n",
    "X_test = test_df.iloc[:, 2:].values\n",
    "y_train = train_df.iloc[:, 1].values\n",
    "y_test = test_df.iloc[:, 1].values\n",
    "\n",
    "# Encoding Dependent Variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# Before PCA\n",
    "bc = BayesClassifier()\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred_before = bc.predict(X_test)\n",
    "\n",
    "final_df_before = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_before})\n",
    "accuracy = accuracy_score(y_test, y_pred_before)\n",
    "print(f\"The Accuracy of this model before PCA is {accuracy * 100}%\")\n",
    "\n",
    "# Applying PCA\n",
    "X_train = pca(X_train)\n",
    "\n",
    "# After PCA\n",
    "bc = BayesClassifier()\n",
    "bc.fit(X_train, y_train)\n",
    "X_test = pca(X_test)  \n",
    "y_pred_after = bc.predict(X_test)\n",
    "\n",
    "final_df_after = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_after})\n",
    "accuracy = accuracy_score(y_test, y_pred_after)\n",
    "print(f\"The Accuracy of this model after PCA is {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55a2c479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of this model is 85.0%\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Principal Component Analysis (PCA) Class\n",
    "class PrincipalComponentAnalysis:\n",
    "    def __init__(self, n_components=0):\n",
    "        self.num_components = n_components\n",
    "\n",
    "    def fit(self, X):\n",
    "        if self.num_components == 0:\n",
    "            self.num_components = round(0.95 * len(X))\n",
    "        self.mean_vector = np.mean(X, axis=0)\n",
    "        self.covariance_matrix = np.cov(X, rowvar=False)\n",
    "        self.eigen_values, self.eigen_vectors = np.linalg.eig(self.covariance_matrix)\n",
    "        ind = np.argsort(self.eigen_values)[::-1]\n",
    "        self.sorted_eigen_values = self.eigen_values[ind]\n",
    "        self.sorted_eigen_vectors = self.eigen_vectors[ind]\n",
    "        self.final_eigen_vectors = self.sorted_eigen_vectors[:, :self.num_components]\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = np.dot(X, self.final_eigen_vectors)\n",
    "        return X_transformed\n",
    "\n",
    "# Bayes Classifier Class\n",
    "class BayesianClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes, self.class_counts = np.unique(y_train, return_counts=True)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.total_data_points = len(y_train)\n",
    "        self.apriori_probabilities = self.class_counts / self.total_data_points\n",
    "        self.class_split_training_data = {}\n",
    "        \n",
    "        for c in self.classes:\n",
    "            self.class_split_training_data[c] = []\n",
    "            for j in range(len(y_train)):\n",
    "                if c == y_train[j]:\n",
    "                    self.class_split_training_data[c].append(X_train[j])\n",
    "            self.class_split_training_data[c] = np.array(self.class_split_training_data[c])\n",
    "        \n",
    "        self.mean_vectors = [np.mean(self.class_split_training_data[c], axis=0) for c in self.classes]\n",
    "        self.covariance_matrices = [np.cov(self.class_split_training_data[c], rowvar=False) for c in self.classes]\n",
    "        self.inverse_covariance_matrices = [np.linalg.inv(self.covariance_matrices[c]) for c in range(len(self.classes))]\n",
    "        self.dimensions = len(X_train[0])\n",
    "        self.det_covariance_matrices = [sp.Matrix(self.covariance_matrices[c]).det() for c in range(len(self.classes))]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for X in X_test:\n",
    "            probability_values = {}\n",
    "            class_count = 0\n",
    "            for c in self.classes:\n",
    "                p_xw = np.exp(-0.5 * np.dot(np.dot((X - self.mean_vectors[class_count]).T, self.inverse_covariance_matrices[class_count]), (X - self.mean_vectors[class_count]))) / (((2 * np.pi) ** (self.dimensions / 2)) * np.power(self.det_covariance_matrices[class_count], 0.5))\n",
    "                p_wx = p_xw * self.apriori_probabilities[class_count]\n",
    "                probability_values[c] = p_wx\n",
    "                class_count += 1\n",
    "            y_pred.append(max(probability_values, key=probability_values.get))\n",
    "        y_pred = np.array(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "# Data Import and Preprocessing\n",
    "dataset = pd.read_csv(\"gender.csv\")\n",
    "types = dataset.iloc[:, 1].unique()\n",
    "test_df = pd.DataFrame()\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "# Split the dataset into test and train\n",
    "for t in types:\n",
    "    type_df = dataset[dataset.iloc[:, 1] == t]\n",
    "    train_df = pd.concat([train_df, type_df.iloc[10:]])\n",
    "    test_df = pd.concat([test_df, type_df.iloc[:10]])\n",
    "\n",
    "X_train = train_df.iloc[:, 2:].values\n",
    "X_test = test_df.iloc[:, 2:].values\n",
    "y_train = train_df.iloc[:, 1].values\n",
    "y_test = test_df.iloc[:, 1].values\n",
    "\n",
    "# Encoding Dependent Variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# Initialize and fit the PCA model\n",
    "pca = PrincipalComponentAnalysis()\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Transform the data using PCA\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Initialize and fit the Bayesian Classifier\n",
    "bc = BayesianClassifier()\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"The Accuracy of this model is {accuracy * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "744221b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 102>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Initialize and fit the Bayesian Classifier\u001b[39;00m\n\u001b[0;32m    101\u001b[0m bc \u001b[38;5;241m=\u001b[39m BayesianClassifier()\n\u001b[1;32m--> 102\u001b[0m \u001b[43mbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m    105\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m bc\u001b[38;5;241m.\u001b[39mpredict(X_test_pca)\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mBayesianClassifier.fit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse_covariance_matrices \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_matrices[c]) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses))]\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdet_covariance_matrices \u001b[38;5;241m=\u001b[39m [sp\u001b[38;5;241m.\u001b[39mMatrix(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_matrices[c])\u001b[38;5;241m.\u001b[39mdet() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses))]\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse_covariance_matrices \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_matrices[c]) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses))]\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdet_covariance_matrices \u001b[38;5;241m=\u001b[39m [\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_matrices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses))]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\matrices.py:131\u001b[0m, in \u001b[0;36mMatrixDeterminant.det\u001b[1;34m(self, method, iszerofunc)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdet\u001b[39m(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbareiss\u001b[39m\u001b[38;5;124m\"\u001b[39m, iszerofunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_det\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miszerofunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miszerofunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\determinant.py:670\u001b[0m, in \u001b[0;36m_det\u001b[1;34m(M, method, iszerofunc)\u001b[0m\n\u001b[0;32m    668\u001b[0m     det \u001b[38;5;241m=\u001b[39m _det_DOM(M[b, b])\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbareiss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 670\u001b[0m     det \u001b[38;5;241m=\u001b[39m \u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_det_bareiss\u001b[49m\u001b[43m(\u001b[49m\u001b[43miszerofunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miszerofunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mberkowitz\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    672\u001b[0m     det \u001b[38;5;241m=\u001b[39m M[b, b]\u001b[38;5;241m.\u001b[39m_eval_det_berkowitz()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\matrices.py:107\u001b[0m, in \u001b[0;36mMatrixDeterminant._eval_det_bareiss\u001b[1;34m(self, iszerofunc)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_eval_det_bareiss\u001b[39m(\u001b[38;5;28mself\u001b[39m, iszerofunc\u001b[38;5;241m=\u001b[39m_is_zero_after_expand_mul):\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_det_bareiss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miszerofunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miszerofunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\determinant.py:743\u001b[0m, in \u001b[0;36m_det_bareiss\u001b[1;34m(M, iszerofunc)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m M\u001b[38;5;241m.\u001b[39mone\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;66;03m# sympy/matrices/tests/test_matrices.py contains a test that\u001b[39;00m\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;66;03m# suggests that the determinant of a 0 x 0 matrix is one, by\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;66;03m# convention.\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbareiss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\determinant.py:732\u001b[0m, in \u001b[0;36m_det_bareiss.<locals>.bareiss\u001b[1;34m(mat, cumm)\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cancel(ret)\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sign\u001b[38;5;241m*\u001b[39m\u001b[43mbareiss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpivot_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\determinant.py:732\u001b[0m, in \u001b[0;36m_det_bareiss.<locals>.bareiss\u001b[1;34m(mat, cumm)\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cancel(ret)\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sign\u001b[38;5;241m*\u001b[39mbareiss(\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m, pivot_val)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\repmatrix.py:340\u001b[0m, in \u001b[0;36mMutableRepMatrix._new\u001b[1;34m(cls, copy, *args, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m     rows, cols, flat_list \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     rows, cols, flat_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_creation_inputs(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    341\u001b[0m     flat_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(flat_list) \u001b[38;5;66;03m# create a shallow copy\u001b[39;00m\n\u001b[0;32m    343\u001b[0m rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_list_to_DomainMatrix(rows, cols, flat_list)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\matrices.py:1127\u001b[0m, in \u001b[0;36mMatrixBase._handle_creation_inputs\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     flat_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows):\n\u001b[0;32m   1126\u001b[0m         flat_list\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m-> 1127\u001b[0m             [\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_sympify(op(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_sympify(i), \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_sympify(j)))\n\u001b[0;32m   1128\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cols)])\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# Matrix(2, 2, [1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_sequence(args[\u001b[38;5;241m2\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\matrices.py:1127\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     flat_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows):\n\u001b[0;32m   1126\u001b[0m         flat_list\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m-> 1127\u001b[0m             [\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_sympify(\u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1128\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cols)])\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# Matrix(2, 2, [1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_sequence(args[\u001b[38;5;241m2\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\matrices\\determinant.py:725\u001b[0m, in \u001b[0;36m_det_bareiss.<locals>.bareiss.<locals>.entry\u001b[1;34m(i, j)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentry\u001b[39m(i, j):\n\u001b[1;32m--> 725\u001b[0m     ret \u001b[38;5;241m=\u001b[39m (pivot_val\u001b[38;5;241m*\u001b[39mtmp_mat[i, j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43mmat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpivot_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtmp_mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m/\u001b[39m cumm\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _get_intermediate_simp_bool(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _dotprodsimp(ret)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\core\\decorators.py:65\u001b[0m, in \u001b[0;36m__sympifyit.<locals>.__sympifyit_wrapper\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(b, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_op_priority\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     64\u001b[0m         b \u001b[38;5;241m=\u001b[39m sympify(b, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SympifyError:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sympy\\core\\numbers.py:1297\u001b[0m, in \u001b[0;36mFloat.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Number) \u001b[38;5;129;01mand\u001b[39;00m global_parameters\u001b[38;5;241m.\u001b[39mevaluate:\n\u001b[0;32m   1296\u001b[0m     rhs, prec \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_as_mpf_op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prec)\n\u001b[1;32m-> 1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Float\u001b[38;5;241m.\u001b[39m_new(\u001b[43mmlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmpf_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mpf_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m, prec)\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Number\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpmath\\libmp\\libmpf.py:894\u001b[0m, in \u001b[0;36mpython_mpf_mul\u001b[1;34m(s, t, prec, rnd)\u001b[0m\n\u001b[0;32m    892\u001b[0m bc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(man\u001b[38;5;241m>>\u001b[39mbc)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prec:\n\u001b[1;32m--> 894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnormalize1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mman\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msexp\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (sign, man, sexp\u001b[38;5;241m+\u001b[39mtexp, bc)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpmath\\libmp\\libmpf.py:212\u001b[0m, in \u001b[0;36m_normalize1\u001b[1;34m(sign, man, exp, bc, prec, rnd)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalize1\u001b[39m(sign, man, exp, bc, prec, rnd):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124;03m\"\"\"same as normalize, but with the added condition that\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m       man is odd or zero\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m man:\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fzero\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m prec:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Principal Component Analysis (PCA) Class\n",
    "class PrincipalComponentAnalysis:\n",
    "    def __init__(self, n_components=0.95):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean_vector = np.mean(X, axis=0)\n",
    "        self.covariance_matrix = np.cov(X, rowvar=False)\n",
    "        self.eigen_values, self.eigen_vectors = np.linalg.eig(self.covariance_matrix)\n",
    "        ind = np.argsort(self.eigen_values)[::-1]\n",
    "        self.sorted_eigen_values = self.eigen_values[ind]\n",
    "        \n",
    "        if self.n_components >= 1:\n",
    "            self.num_components = int(self.n_components)\n",
    "        else:\n",
    "            total_variance = np.sum(self.sorted_eigen_values)\n",
    "            self.selected_eigen_values = []\n",
    "            cum_variance = 0\n",
    "            i = 0\n",
    "            while cum_variance < 0.95 * total_variance:\n",
    "                cum_variance += self.sorted_eigen_values[i]\n",
    "                self.selected_eigen_values.append(self.sorted_eigen_values[i])\n",
    "                i += 1\n",
    "            self.num_components = len(self.selected_eigen_values)\n",
    "        \n",
    "        self.sorted_eigen_vectors = self.eigen_vectors[ind]\n",
    "        self.final_eigen_vectors = self.sorted_eigen_vectors[:, :self.num_components]\n",
    "\n",
    "    def transform(self, X):\n",
    "        X1 = np.dot(X, self.final_eigen_vectors)\n",
    "        return X1\n",
    "\n",
    "# Bayesian Classifier Class\n",
    "class BayesianClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes, self.class_counts = np.unique(y_train, return_counts=True)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.total_data_points = len(y_train)\n",
    "        self.apriori_probabilities = self.class_counts / self.total_data_points\n",
    "        self.class_split_training_data = {}\n",
    "        \n",
    "        for c in self.classes:\n",
    "            self.class_split_training_data[c] = []\n",
    "            for j in range(len(y_train)):\n",
    "                if c == y_train[j]:\n",
    "                    self.class_split_training_data[c].append(X_train[j])\n",
    "            self.class_split_training_data[c] = np.array(self.class_split_training_data[c])\n",
    "        \n",
    "        self.mean_vectors = [np.mean(self.class_split_training_data[c], axis=0) for c in self.classes]\n",
    "        self.covariance_matrices = [np.cov(self.class_split_training_data[c], rowvar=False) for c in self.classes]\n",
    "        self.inverse_covariance_matrices = [np.linalg.inv(self.covariance_matrices[c]) for c in range(len(self.classes))]\n",
    "        self.dimensions = len(X_train[0])\n",
    "        self.det_covariance_matrices = [sp.Matrix(self.covariance_matrices[c]).det() for c in range(len(self.classes))]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for X in X_test:\n",
    "            probability_values = {}\n",
    "            class_count = 0\n",
    "            for c in self.classes:\n",
    "                p_xw = np.exp(-0.5 * np.dot(np.dot((X - self.mean_vectors[class_count]).T, self.inverse_covariance_matrices[class_count]), (X - self.mean_vectors[class_count]))) / (((2 * np.pi) ** (self.dimensions / 2)) * np.power(self.det_covariance_matrices[class_count], 0.5))\n",
    "                p_wx = p_xw * self.apriori_probabilities[class_count]\n",
    "                probability_values[c] = p_wx\n",
    "                class_count += 1\n",
    "            y_pred.append(max(probability_values, key=probability_values.get))\n",
    "        y_pred = np.array(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "# Data Import and Preprocessing\n",
    "dataset = pd.read_csv('face.csv')\n",
    "dataset = dataset.fillna(dataset.mean())\n",
    "\n",
    "# Test-Train Split\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Initialize and fit the PCA model\n",
    "pca = PrincipalComponentAnalysis()\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Transform the data using PCA\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Initialize and fit the Bayesian Classifier\n",
    "bc = BayesianClassifier()\n",
    "bc.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bc.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"The Accuracy of this model is {accuracy * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77d864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
